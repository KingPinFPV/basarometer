#!/usr/bin/env python3
"""
Israeli Network Expansion System for Basarometer V6.0
Mission: Create extraction templates for 5 new Israeli retail networks
Target: Expand from 6 to 11 networks, reaching 100+ unified products
Date: 2025-06-27
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any

class IsraeliNetworkExpansionSystem:
    def __init__(self):
        self.target_networks = {
            '◊û◊¢◊ì◊†◊ô_◊í◊ï◊®◊û◊î': {
                'hebrew_name': '◊û◊¢◊ì◊†◊ô ◊í◊ï◊®◊û◊î',
                'english_name': 'Maadanei Gourmet',
                'url_pattern': 'gourmet',
                'focus': 'premium kosher meat',
                'expected_products': 25,
                'price_range': 'premium',
                'specialties': ['wagyu', 'angus', 'kosher_premium'],
                'target_audience': 'high_end_consumers'
            },
            '◊°◊ï◊§◊®_◊ì◊ô◊ú': {
                'hebrew_name': '◊°◊ï◊§◊® ◊ì◊ô◊ú',
                'english_name': 'Super Deal',
                'url_pattern': 'superdeal',
                'focus': 'discount bulk meat',
                'expected_products': 20,
                'price_range': 'budget',
                'specialties': ['bulk_packages', 'family_portions'],
                'target_audience': 'budget_conscious_families'
            },
            '◊ô◊ô◊†◊ï◊™_◊ë◊ô◊™◊ü': {
                'hebrew_name': '◊ô◊ô◊†◊ï◊™ ◊ë◊ô◊™◊ü',
                'english_name': 'Yeinot Bitan',
                'url_pattern': 'bitan',
                'focus': 'specialty meat cuts',
                'expected_products': 18,
                'price_range': 'mid_premium',
                'specialties': ['specialty_cuts', 'imported_meat'],
                'target_audience': 'specialty_seekers'
            },
            '◊ê◊ï◊©◊®_◊¢◊ì': {
                'hebrew_name': '◊ê◊ï◊©◊® ◊¢◊ì',
                'english_name': 'Osher Ad',
                'url_pattern': 'osher',
                'focus': 'neighborhood convenience',
                'expected_products': 15,
                'price_range': 'standard',
                'specialties': ['local_favorites', 'convenient_portions'],
                'target_audience': 'neighborhood_shoppers'
            },
            '◊ó◊¶◊ô_◊ó◊ô◊†◊ù': {
                'hebrew_name': '◊ó◊¶◊ô ◊ó◊ô◊†◊ù',
                'english_name': 'Hetzi Hinam',
                'url_pattern': 'hetzihinam',
                'focus': 'discount chain',
                'expected_products': 22,
                'price_range': 'budget',
                'specialties': ['promotional_deals', 'bulk_discounts'],
                'target_audience': 'deal_hunters'
            }
        }
        
    def create_network_extraction_templates(self) -> Dict[str, str]:
        """Create extraction templates for each new Israeli network"""
        
        templates = {}
        
        for network_key, network_info in self.target_networks.items():
            template_content = self.generate_network_template(network_key, network_info)
            filename = f"extract_{network_info['url_pattern']}_network.py"
            
            # Write template to file
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(template_content)
            
            templates[network_key] = filename
            print(f"‚úÖ Created extraction template: {filename}")
            
        return templates
    
    def generate_network_template(self, network_key: str, network_info: Dict) -> str:
        """Generate Python extraction template for a specific network"""
        
        template = f'''#!/usr/bin/env python3
"""
{network_info['hebrew_name']} ({network_info['english_name']}) Network Extractor
Focus: {network_info['focus']}
Expected Products: {network_info['expected_products']}
Price Range: {network_info['price_range']}
Generated: {datetime.now().isoformat()}
"""

import requests
import json
from datetime import datetime
from typing import List, Dict, Any, Optional
import re
from bs4 import BeautifulSoup

class {network_info['english_name'].replace(' ', '')}Extractor:
    def __init__(self):
        self.network_name = "{network_info['hebrew_name']}"
        self.network_key = "{network_key}"
        self.url_pattern = "{network_info['url_pattern']}"
        self.focus = "{network_info['focus']}"
        self.price_range = "{network_info['price_range']}"
        self.specialties = {network_info['specialties']}
        self.target_products = {network_info['expected_products']}
        
        # Network-specific selectors (to be customized per actual website)
        self.selectors = {{
            'product_container': '.product-item, .meat-product, .item',
            'product_name': '.product-name, .title, h3, .item-title',
            'product_price': '.price, .cost, .amount, .product-price',
            'product_unit': '.unit, .weight, .measure',
            'product_image': '.product-image img, .item-image img',
            'product_description': '.description, .product-desc, .details'
        }}
        
        # Price range adjustments based on network positioning
        self.price_multipliers = {{
            'premium': 1.2,      # {network_info['hebrew_name']} premium pricing
            'mid_premium': 1.1,  # Above standard
            'standard': 1.0,     # Market standard  
            'budget': 0.85       # Below market average
        }}
        
    def extract_products(self) -> List[Dict[str, Any]]:
        """
        Extract meat products from {network_info['hebrew_name']}
        Target: {network_info['expected_products']} products
        """
        
        print(f"üè™ Starting extraction for {{self.network_name}}")
        print(f"üéØ Target: {{self.target_products}} products")
        print(f"üí∞ Price range: {{self.price_range}}")
        
        # Simulate extraction (replace with actual web scraping)
        products = self.simulate_network_extraction()
        
        # Apply network-specific classification
        classified_products = []
        
        for product in products:
            classified_product = self.classify_and_enhance_product(product)
            if classified_product:
                classified_products.append(classified_product)
        
        print(f"‚úÖ Extracted {{len(classified_products)}} products from {{self.network_name}}")
        
        # Save results
        self.save_extraction_results(classified_products)
        
        return classified_products
    
    def simulate_network_extraction(self) -> List[Dict[str, Any]]:
        """
        Simulate product extraction for {network_info['hebrew_name']}
        (Replace with actual website scraping implementation)
        """
        
        # Base product templates specific to this network's specialties
        base_products = self.get_network_specific_products()
        
        products = []
        price_multiplier = self.price_multipliers[self.price_range]
        
        for i, base_product in enumerate(base_products[:self.target_products]):
            product = {{
                'id': f"{{self.network_key}}_{{i+1:03d}}",
                'name': base_product['name'],
                'price': round(base_product['base_price'] * price_multiplier, 2),
                'unit': base_product.get('unit', '◊ß◊¥◊í'),
                'category': base_product.get('category', '◊ë◊©◊® ◊ï◊¢◊ï◊£'),
                'description': base_product.get('description', ''),
                'source': f"{{self.network_name}}_extraction",
                'network': self.network_key,
                'extraction_timestamp': datetime.now().isoformat()
            }}
            products.append(product)
        
        return products
    
    def get_network_specific_products(self) -> List[Dict[str, Any]]:
        """
        Get product templates specific to {network_info['hebrew_name']}'s focus and specialties
        """
        
        {self.generate_network_specific_products(network_info)}
        
        return products
    
    def classify_and_enhance_product(self, product: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Apply {network_info['hebrew_name']}-specific classification and enhancement
        """
        
        # Enhanced meat classification
        meat_classification = self.enhanced_meat_classification(
            product['name'], 
            product.get('description', '')
        )
        
        if not meat_classification['is_meat'] or meat_classification['quality_score'] < 60:
            return None
        
        # Apply network-specific enhancements
        enhanced_product = {{
            **product,
            'meat_classification': meat_classification,
            'network_specialties': self.identify_network_specialties(product),
            'quality_score': self.calculate_network_quality_score(product, meat_classification),
            'consumer_appeal': self.assess_consumer_appeal(product),
            'price_competitiveness': self.assess_price_competitiveness(product)
        }}
        
        return enhanced_product
    
    def enhanced_meat_classification(self, name: str, description: str) -> Dict[str, Any]:
        """
        Enhanced meat classification system optimized for {network_info['hebrew_name']}
        """
        
        text = f"{{name}} {{description}}".lower()
        
        # Network-specific meat indicators
        meat_indicators = [
            '◊ë◊©◊®', '◊¢◊ï◊£', '◊ë◊ß◊®', '◊õ◊ë◊©', '◊¢◊í◊ú', '◊§◊®◊í◊ô◊™', '◊©◊†◊ô◊¶◊ú', '◊ß◊¶◊ô◊¶◊ï◊™',
            '◊ê◊†◊ò◊®◊ô◊ß◊ï◊ò', '◊§◊ô◊ú◊î', '◊¶◊ú◊ô', '◊°◊ò◊ô◊ô◊ß', '◊†◊ß◊†◊ô◊ß', '◊†◊™◊ó', '◊õ◊™◊£'
        ]
        
        # Quality indicators specific to network specialties
        quality_indicators = {network_info['specialties']}
        
        meat_score = sum(10 for indicator in meat_indicators if indicator in text)
        quality_score = 70 + (meat_score * 2)  # Base score for this network
        
        # Apply network-specific quality boost
        if any(specialty.replace('_', ' ') in text for specialty in self.specialties):
            quality_score += 15
        
        return {{
            'is_meat': meat_score > 0,
            'meat_score': meat_score,
            'quality_score': min(quality_score, 95),
            'network_specialty_match': any(specialty.replace('_', ' ') in text for specialty in self.specialties),
            'classification_confidence': min(0.9, (meat_score / 20))
        }}
    
    def identify_network_specialties(self, product: Dict[str, Any]) -> List[str]:
        """
        Identify which of {network_info['hebrew_name']}'s specialties this product matches
        """
        
        text = f"{{product['name']}} {{product.get('description', '')}}".lower()
        matched_specialties = []
        
        specialty_keywords = {{
            'premium_kosher': ['◊õ◊©◊®', '◊û◊î◊ì◊®◊ô◊ü', '◊ë◊ì◊¥◊•', '◊§◊®◊û◊ô◊ï◊ù'],
            'wagyu': ['◊ï◊ï◊ê◊í◊ô◊ï', 'wagyu', '◊ô◊§◊†◊ô'],
            'angus': ['◊ê◊†◊í◊ï◊°', 'angus', '◊ê◊û◊®◊ô◊ß◊ê◊ô'],
            'bulk_packages': ['◊û◊ê◊®◊ñ', '◊ó◊ë◊ô◊ú◊î', '◊û◊©◊§◊ó◊™◊ô', '◊í◊ì◊ï◊ú'],
            'specialty_cuts': ['◊û◊ô◊ï◊ó◊ì', '◊†◊ì◊ô◊®', '◊û◊ï◊ë◊ó◊®', '◊ê◊ô◊õ◊ï◊™◊ô'],
            'imported_meat': ['◊ô◊ë◊ï◊ê', '◊ê◊®◊í◊†◊ò◊ô◊†◊ê◊ô', '◊ê◊û◊®◊ô◊ß◊ê◊ô', '◊ê◊ô◊®◊ï◊§◊ê◊ô'],
            'local_favorites': ['◊ô◊©◊®◊ê◊ú◊ô', '◊û◊ß◊ï◊û◊ô', '◊ê◊ñ◊ï◊®◊ô'],
            'promotional_deals': ['◊û◊ë◊¶◊¢', '◊î◊†◊ó◊î', '◊û◊ó◊ô◊® ◊û◊ô◊ï◊ó◊ì', '◊ó◊°◊õ◊ï◊ü']
        }}
        
        for specialty in self.specialties:
            keywords = specialty_keywords.get(specialty, [])
            if any(keyword in text for keyword in keywords):
                matched_specialties.append(specialty)
        
        return matched_specialties
    
    def calculate_network_quality_score(self, product: Dict[str, Any], meat_classification: Dict[str, Any]) -> float:
        """
        Calculate quality score adjusted for {network_info['hebrew_name']}'s positioning
        """
        
        base_score = meat_classification['quality_score']
        
        # Network positioning adjustments
        positioning_adjustment = {{
            'premium': 10,
            'mid_premium': 5,
            'standard': 0,
            'budget': -5
        }}.get(self.price_range, 0)
        
        # Specialty match bonus
        specialty_bonus = len(self.identify_network_specialties(product)) * 3
        
        final_score = base_score + positioning_adjustment + specialty_bonus
        
        return min(95, max(60, final_score))
    
    def assess_consumer_appeal(self, product: Dict[str, Any]) -> Dict[str, Any]:
        """
        Assess consumer appeal based on {network_info['hebrew_name']}'s target audience
        """
        
        appeal_factors = {{
            'target_audience_match': self.matches_target_audience(product),
            'price_attractiveness': self.assess_price_attractiveness(product),
            'specialty_appeal': len(self.identify_network_specialties(product)) > 0,
            'network_brand_value': self.get_network_brand_value()
        }}
        
        overall_appeal = sum([
            appeal_factors['target_audience_match'] * 0.3,
            appeal_factors['price_attractiveness'] * 0.3,
            appeal_factors['specialty_appeal'] * 0.2,
            appeal_factors['network_brand_value'] * 0.2
        ])
        
        return {{
            'overall_score': round(overall_appeal, 2),
            'factors': appeal_factors,
            'target_audience': "{network_info['target_audience']}"
        }}
    
    def matches_target_audience(self, product: Dict[str, Any]) -> float:
        """
        Check if product matches {network_info['hebrew_name']}'s target audience
        """
        
        target_indicators = {{
            'high_end_consumers': ['◊§◊®◊û◊ô◊ï◊ù', '◊û◊ï◊ë◊ó◊®', '◊ê◊ô◊õ◊ï◊™◊ô', '◊ô◊ï◊ß◊®◊™◊ô'],
            'budget_conscious_families': ['◊û◊©◊§◊ó◊™◊ô', '◊ó◊°◊õ◊ï◊ü', '◊õ◊ú◊õ◊ú◊ô', '◊û◊ê◊®◊ñ'],
            'specialty_seekers': ['◊û◊ô◊ï◊ó◊ì', '◊†◊ì◊ô◊®', '◊ô◊ë◊ï◊ê', '◊ê◊ô◊õ◊ï◊™ ◊í◊ë◊ï◊î◊î'],
            'neighborhood_shoppers': ['◊†◊ï◊ó', '◊ñ◊û◊ô◊ü', '◊ß◊®◊ï◊ë', '◊û◊ß◊ï◊û◊ô'],
            'deal_hunters': ['◊û◊ë◊¶◊¢', '◊î◊†◊ó◊î', '◊û◊ó◊ô◊® ◊û◊ô◊ï◊ó◊ì', '◊ó◊°◊õ◊ï◊ü']
        }}
        
        text = f"{{product['name']}} {{product.get('description', '')}}".lower()
        indicators = target_indicators.get("{network_info['target_audience']}", [])
        
        matches = sum(1 for indicator in indicators if indicator in text)
        return min(1.0, matches / 2)
    
    def assess_price_attractiveness(self, product: Dict[str, Any]) -> float:
        """
        Assess price attractiveness for {network_info['hebrew_name']}'s positioning
        """
        
        price = product.get('price', 0)
        
        # Price attractiveness based on network positioning
        attractiveness_ranges = {{
            'premium': (100, 300),      # High prices expected and accepted
            'mid_premium': (50, 150),   # Moderate premium acceptable
            'standard': (30, 100),      # Standard market prices
            'budget': (20, 80)          # Lower prices highly valued
        }}
        
        min_price, max_price = attractiveness_ranges[self.price_range]
        
        if min_price <= price <= max_price:
            return 1.0
        elif price < min_price:
            return 0.8  # Too cheap might indicate quality concerns
        else:
            return max(0.2, 1.0 - ((price - max_price) / max_price))
    
    def get_network_brand_value(self) -> float:
        """
        Get brand value score for {network_info['hebrew_name']}
        """
        
        brand_values = {{
            'premium': 0.9,
            'mid_premium': 0.8,
            'standard': 0.7,
            'budget': 0.6
        }}
        
        return brand_values.get(self.price_range, 0.7)
    
    def assess_price_competitiveness(self, product: Dict[str, Any]) -> Dict[str, Any]:
        """
        Assess price competitiveness within {network_info['hebrew_name']}'s segment
        """
        
        price = product.get('price', 0)
        
        # Competitive positioning for this network
        positioning = {{
            'network_segment': self.price_range,
            'expected_premium': self.price_multipliers[self.price_range] - 1.0,
            'competitive_advantage': self.get_competitive_advantages(),
            'price_justification': self.get_price_justification(product)
        }}
        
        return positioning
    
    def get_competitive_advantages(self) -> List[str]:
        """
        Get competitive advantages for {network_info['hebrew_name']}
        """
        
        advantages = {{
            'premium': ['◊õ◊©◊®◊ï◊™ ◊û◊î◊ï◊ì◊®◊™', '◊ê◊ô◊õ◊ï◊™ ◊û◊ï◊õ◊ó◊™', '◊ô◊ë◊ï◊ê ◊û◊ï◊ë◊ó◊®', '◊©◊ô◊®◊ï◊™ ◊ê◊ô◊©◊ô'],
            'mid_premium': ['◊ê◊ô◊õ◊ï◊™ ◊ò◊ï◊ë◊î', '◊û◊ë◊ó◊® ◊®◊ó◊ë', '◊û◊ó◊ô◊®◊ô◊ù ◊î◊ï◊í◊†◊ô◊ù', '◊ñ◊û◊ô◊†◊ï◊™ ◊í◊ë◊ï◊î◊î'],
            'standard': ['◊û◊ó◊ô◊®◊ô◊ù ◊™◊ó◊®◊ï◊™◊ô◊ô◊ù', '◊†◊ï◊ó◊ï◊™ ◊ß◊†◊ô◊î', '◊ñ◊û◊ô◊†◊ï◊™', '◊ê◊û◊ô◊†◊ï◊™'],
            'budget': ['◊û◊ó◊ô◊®◊ô◊ù ◊†◊û◊ï◊õ◊ô◊ù', '◊û◊ë◊¶◊¢◊ô◊ù', '◊ó◊°◊õ◊ï◊ü ◊û◊©◊§◊ó◊™◊ô', '◊†◊í◊ô◊©◊ï◊™']
        }}
        
        return advantages.get(self.price_range, [])
    
    def get_price_justification(self, product: Dict[str, Any]) -> str:
        """
        Get price justification for {network_info['hebrew_name']}'s positioning
        """
        
        justifications = {{
            'premium': f"◊û◊ó◊ô◊® ◊§◊®◊û◊ô◊ï◊ù ◊û◊ï◊¶◊ì◊ß ◊ë◊ê◊ô◊õ◊ï◊™ ◊ï◊ë◊õ◊©◊®◊ï◊™ ◊û◊î◊ì◊®◊ô◊ü",
            'mid_premium': f"◊û◊ó◊ô◊® ◊û◊¢◊ú ◊î◊û◊û◊ï◊¶◊¢ ◊û◊ï◊¶◊ì◊ß ◊ë◊û◊ß◊ï◊®◊ô◊ï◊™ ◊ï◊ë◊ê◊ô◊õ◊ï◊™",
            'standard': f"◊û◊ó◊ô◊® ◊©◊ï◊ß ◊î◊ï◊í◊ü ◊ï◊™◊ó◊®◊ï◊™◊ô",
            'budget': f"◊û◊ó◊ô◊® ◊ê◊ò◊®◊ß◊ò◊ô◊ë◊ô ◊¢◊ù ◊¢◊®◊ö ◊û◊ï◊°◊£ ◊û◊©◊§◊ó◊™◊ô"
        }}
        
        return justifications.get(self.price_range, "◊û◊ó◊ô◊® ◊™◊ó◊®◊ï◊™◊ô")
    
    def save_extraction_results(self, products: List[Dict[str, Any]]) -> None:
        """
        Save extraction results for {network_info['hebrew_name']}
        """
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{{self.network_key}}_extraction_{{timestamp}}.json"
        
        results = {{
            'network_info': {{
                'name': self.network_name,
                'key': self.network_key,
                'focus': self.focus,
                'price_range': self.price_range,
                'specialties': self.specialties
            }},
            'extraction_metadata': {{
                'timestamp': datetime.now().isoformat(),
                'target_products': self.target_products,
                'actual_products': len(products),
                'success_rate': len(products) / self.target_products if self.target_products > 0 else 0
            }},
            'products': products,
            'summary': {{
                'total_products': len(products),
                'avg_price': round(sum(p.get('price', 0) for p in products) / len(products), 2) if products else 0,
                'price_range_actual': {{
                    'min': min(p.get('price', 0) for p in products) if products else 0,
                    'max': max(p.get('price', 0) for p in products) if products else 0
                }},
                'quality_scores': {{
                    'avg': round(sum(p.get('quality_score', 0) for p in products) / len(products), 1) if products else 0,
                    'high_quality_count': len([p for p in products if p.get('quality_score', 0) > 80])
                }}
            }}
        }}
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ Results saved to: {{filename}}")
        
def main():
    """
    Main execution function for {network_info['hebrew_name']} extraction
    """
    
    extractor = {network_info['english_name'].replace(' ', '')}Extractor()
    products = extractor.extract_products()
    
    print(f"\\n‚úÖ {{extractor.network_name}} extraction complete!")
    print(f"üìä Products extracted: {{len(products)}}")
    print(f"üéØ Target achievement: {{len(products) / extractor.target_products * 100:.1f}}%")
    
    if products:
        avg_price = sum(p.get('price', 0) for p in products) / len(products)
        print(f"üí∞ Average price: ‚Ç™{{avg_price:.2f}}")
        
        high_quality = len([p for p in products if p.get('quality_score', 0) > 80])
        print(f"‚≠ê High quality products: {{high_quality}} ({{high_quality / len(products) * 100:.1f}}%)")
    
    return products

if __name__ == "__main__":
    main()
'''
        
        return template
    
    def generate_network_specific_products(self, network_info: Dict) -> str:
        """Generate network-specific product templates"""
        
        product_templates = {
            '◊û◊¢◊ì◊†◊ô_◊í◊ï◊®◊û◊î': '''
        products = [
            {'name': '◊ê◊†◊ò◊®◊ô◊ß◊ï◊ò ◊ï◊ï◊ê◊í◊ô◊ï ◊ô◊§◊†◊ô ◊§◊®◊û◊ô◊ï◊ù', 'base_price': 280, 'category': '◊ë◊ß◊® ◊§◊®◊û◊ô◊ï◊ù'},
            {'name': '◊§◊ô◊ú◊î ◊ë◊ß◊® ◊ê◊†◊í◊ï◊° ◊û◊ï◊ë◊ó◊®', 'base_price': 180, 'category': '◊ë◊ß◊® ◊ê◊ô◊õ◊ï◊™◊ô'},
            {'name': '◊¶◊ú◊ô ◊õ◊™◊£ ◊õ◊ë◊© ◊û◊î◊ì◊®◊ô◊ü', 'base_price': 120, 'category': '◊õ◊ë◊© ◊õ◊©◊®'},
            {'name': '◊©◊†◊ô◊¶◊ú ◊¢◊ï◊£ ◊ê◊ï◊®◊í◊†◊ô ◊ó◊ï◊§◊©◊ô', 'base_price': 75, 'category': '◊¢◊ï◊£ ◊ê◊ô◊õ◊ï◊™◊ô'},
            {'name': '◊†◊ß◊†◊ô◊ß◊ô◊ï◊™ ◊ë◊ß◊® ◊õ◊©◊® ◊û◊î◊ì◊®◊ô◊ü', 'base_price': 65, 'category': '◊û◊ï◊¶◊®◊ô ◊ë◊ß◊®'},
            {'name': '◊°◊ò◊ô◊ô◊ß ◊®◊ô◊ë ◊ê◊ô◊ô ◊ê◊û◊®◊ô◊ß◊ê◊ô', 'base_price': 220, 'category': '◊ë◊ß◊® ◊ô◊ë◊ï◊ê'},
            {'name': '◊õ◊™◊£ ◊¢◊í◊ú ◊ò◊®◊ô ◊û◊ß◊ï◊û◊ô', 'base_price': 95, 'category': '◊¢◊í◊ú ◊ê◊ô◊õ◊ï◊™◊ô'},
            {'name': '◊§◊®◊í◊ô◊™ ◊¢◊ï◊£ ◊ú◊ú◊ê ◊ê◊†◊ò◊ô◊ë◊ô◊ï◊ò◊ô◊ß◊î', 'base_price': 55, 'category': '◊¢◊ï◊£ ◊ê◊ï◊®◊í◊†◊ô'},
            {'name': '◊î◊û◊ë◊ï◊®◊í◊® ◊ë◊ß◊® ◊ê◊†◊í◊ï◊° 200◊í◊®', 'base_price': 40, 'category': '◊û◊ï◊¶◊®◊ô ◊ë◊ß◊®'},
            {'name': '◊ß◊ë◊ë ◊õ◊ë◊© ◊û◊™◊ï◊ë◊ú ◊û◊î◊ì◊®◊ô◊ü', 'base_price': 85, 'category': '◊õ◊ë◊© ◊û◊™◊ï◊ë◊ú'},
            {'name': '◊¶◊ú◊¢◊ï◊™ ◊ë◊ß◊® ◊ú◊¢◊ô◊©◊ï◊ü', 'base_price': 130, 'category': '◊ë◊ß◊® ◊¢◊ô◊©◊ï◊ü'},
            {'name': '◊†◊™◊ó ◊ê◊°◊ê◊ì◊ï ◊ê◊®◊í◊†◊ò◊ô◊†◊ê◊ô', 'base_price': 160, 'category': '◊ë◊ß◊® ◊ô◊ë◊ï◊ê'},
            {'name': '◊õ◊†◊§◊ô◊ô◊ù ◊¢◊ï◊£ ◊û◊î◊ì◊®◊ô◊ü', 'base_price': 35, 'category': '◊¢◊ï◊£ ◊õ◊©◊®'},
            {'name': '◊û◊®◊ß ◊¢◊¶◊û◊ï◊™ ◊ë◊ß◊® ◊ê◊ï◊®◊í◊†◊ô', 'base_price': 25, 'category': '◊¢◊¶◊û◊ï◊™'},
            {'name': '◊©◊ï◊ï◊ê◊®◊û◊î ◊õ◊ë◊© ◊û◊ï◊ë◊ó◊®◊™', 'base_price': 90, 'category': '◊õ◊ë◊© ◊û◊™◊ï◊ë◊ú'},
            {'name': '◊°◊ò◊ô◊ô◊ß ◊°◊ú◊û◊ï◊ü ◊ò◊®◊ô ◊ô◊ë◊ï◊ê', 'base_price': 110, 'category': '◊ì◊í◊ô◊ù ◊§◊®◊û◊ô◊ï◊ù'},
            {'name': '◊ó◊ñ◊î ◊¢◊ï◊£ ◊ú◊ú◊ê ◊¢◊ï◊®', 'base_price': 60, 'category': '◊¢◊ï◊£ ◊ì◊ú ◊©◊ï◊û◊ü'},
            {'name': '◊ß◊¶◊ô◊¶◊ï◊™ ◊ë◊ß◊® ◊ë◊¢◊ë◊ï◊ì◊™ ◊ô◊ì', 'base_price': 70, 'category': '◊û◊ï◊¶◊®◊ô ◊ë◊ß◊®'},
            {'name': '◊§◊ô◊ú◊î ◊õ◊ë◊© ◊û◊ï◊ë◊ó◊®', 'base_price': 140, 'category': '◊õ◊ë◊© ◊ê◊ô◊õ◊ï◊™◊ô'},
            {'name': '◊¢◊ï◊£ ◊©◊ú◊ù ◊ê◊ï◊®◊í◊†◊ô', 'base_price': 80, 'category': '◊¢◊ï◊£ ◊©◊ú◊ù'},
            {'name': '◊†◊™◊ó ◊¶◊ï◊ï◊ê◊® ◊ë◊ß◊® ◊ú◊ë◊ô◊©◊ï◊ú ◊ê◊ô◊ò◊ô', 'base_price': 55, 'category': '◊ë◊ß◊® ◊ë◊ô◊©◊ï◊ú'},
            {'name': '◊õ◊®◊¢◊ô◊ô◊ù ◊¢◊ï◊£ ◊û◊ï◊ë◊ó◊®◊ï◊™', 'base_price': 30, 'category': '◊¢◊ï◊£ ◊ó◊ú◊ß◊ô◊ù'},
            {'name': '◊°◊ò◊ô◊ô◊ß ◊ò◊ô-◊ë◊ï◊ü ◊ê◊û◊®◊ô◊ß◊ê◊ô', 'base_price': 190, 'category': '◊ë◊ß◊® ◊§◊®◊û◊ô◊ï◊ù'},
            {'name': '◊©◊ï◊ß◊ô◊ô◊ù ◊õ◊ë◊© ◊ú◊ë◊ô◊©◊ï◊ú', 'base_price': 75, 'category': '◊õ◊ë◊© ◊ë◊ô◊©◊ï◊ú'},
            {'name': '◊î◊û◊ë◊ï◊®◊í◊® ◊¢◊ï◊£ ◊ê◊ï◊®◊í◊†◊ô', 'base_price': 35, 'category': '◊û◊ï◊¶◊®◊ô ◊¢◊ï◊£'},
        ]''',
            '◊°◊ï◊§◊®_◊ì◊ô◊ú': '''
        products = [
            {'name': '◊û◊ê◊®◊ñ ◊§◊®◊í◊ô◊ï◊™ ◊¢◊ï◊£ ◊û◊©◊§◊ó◊™◊ô 2 ◊ß◊¥◊í', 'base_price': 55, 'category': '◊¢◊ï◊£ ◊û◊ê◊®◊ñ◊ô◊ù'},
            {'name': '◊ó◊ë◊ô◊ú◊™ ◊†◊ß◊†◊ô◊ß◊ô◊ï◊™ 1 ◊ß◊¥◊í', 'base_price': 35, 'category': '◊†◊ß◊†◊ô◊ß◊ô◊ï◊™ ◊ó◊°◊õ◊ï◊ü'},
            {'name': '◊õ◊™◊£ ◊õ◊ë◊© ◊û◊ï◊ß◊§◊ê ◊ú◊ë◊ô◊©◊ï◊ú', 'base_price': 65, 'category': '◊õ◊ë◊© ◊ó◊°◊õ◊ï◊ü'},
            {'name': '◊©◊ï◊ß◊ô◊ô◊ù ◊¢◊ï◊£ ◊ó◊ë◊ô◊ú◊î 1.5 ◊ß◊¥◊í', 'base_price': 40, 'category': '◊¢◊ï◊£ ◊ó◊°◊õ◊ï◊ü'},
            {'name': '◊ê◊†◊ò◊®◊ô◊ß◊ï◊ò ◊ë◊ß◊® ◊ë◊û◊ë◊¶◊¢', 'base_price': 75, 'category': '◊ë◊ß◊® ◊ë◊û◊ë◊¶◊¢'},
            {'name': '◊ß◊¶◊ô◊¶◊ï◊™ ◊¢◊ï◊£ ◊ß◊§◊ï◊ê◊ï◊™ ◊ß◊¥◊í', 'base_price': 28, 'category': '◊û◊ï◊¶◊®◊ô ◊¢◊ï◊£'},
            {'name': '◊ó◊ñ◊î ◊¢◊ï◊£ ◊§◊®◊ï◊° ◊ú◊©◊†◊ô◊¶◊ú', 'base_price': 45, 'category': '◊¢◊ï◊£ ◊û◊ï◊õ◊ü'},
            {'name': '◊¶◊ú◊ô ◊õ◊™◊£ ◊ë◊ß◊® ◊õ◊ú◊õ◊ú◊ô', 'base_price': 80, 'category': '◊ë◊ß◊® ◊õ◊ú◊õ◊ú◊ô'},
            {'name': '◊û◊ê◊®◊ñ ◊õ◊†◊§◊ô◊ô◊ù ◊¢◊ï◊£ 1 ◊ß◊¥◊í', 'base_price': 25, 'category': '◊¢◊ï◊£ ◊û◊ê◊®◊ñ◊ô◊ù'},
            {'name': '◊†◊™◊ó ◊¶◊ï◊ï◊ê◊® ◊ë◊ß◊® ◊ë◊û◊ë◊¶◊¢', 'base_price': 40, 'category': '◊ë◊ß◊® ◊ó◊°◊õ◊ï◊ü'},
            {'name': '◊©◊ï◊ï◊ê◊®◊û◊î ◊¢◊ï◊£ ◊ß◊§◊ï◊ê◊î', 'base_price': 35, 'category': '◊¢◊ï◊£ ◊û◊™◊ï◊ë◊ú'},
            {'name': '◊ß◊ë◊ë ◊ë◊ß◊® ◊ß◊§◊ï◊ê ◊ß◊¥◊í', 'base_price': 50, 'category': '◊ë◊ß◊® ◊û◊™◊ï◊ë◊ú'},
            {'name': '◊¢◊ï◊£ ◊©◊ú◊ù ◊ß◊§◊ï◊ê', 'base_price': 30, 'category': '◊¢◊ï◊£ ◊©◊ú◊ù'},
            {'name': '◊î◊û◊ë◊ï◊®◊í◊® ◊ë◊ß◊® ◊ó◊ë◊ô◊ú◊î 12 ◊ô◊ó', 'base_price': 45, 'category': '◊û◊ï◊¶◊®◊ô ◊ë◊ß◊®'},
            {'name': '◊§◊®◊í◊ô◊ï◊™ ◊¢◊ï◊£ ◊ú◊ú◊ê ◊¢◊ï◊®', 'base_price': 42, 'category': '◊¢◊ï◊£ ◊ì◊ú ◊©◊ï◊û◊ü'},
            {'name': '◊†◊ß◊†◊ô◊ß◊ô◊ï◊™ ◊¢◊ï◊£ ◊ë◊û◊ë◊¶◊¢', 'base_price': 22, 'category': '◊†◊ß◊†◊ô◊ß◊ô◊ï◊™'},
            {'name': '◊õ◊®◊¢◊ô◊ô◊ù ◊¢◊ï◊£ ◊û◊ê◊®◊ñ 1 ◊ß◊¥◊í', 'base_price': 20, 'category': '◊¢◊ï◊£ ◊ó◊°◊õ◊ï◊ü'},
            {'name': '◊¶◊ú◊¢◊ï◊™ ◊ë◊ß◊® ◊ß◊§◊ï◊ê◊ï◊™', 'base_price': 60, 'category': '◊ë◊ß◊® ◊õ◊ú◊õ◊ú◊ô'},
            {'name': '◊©◊ï◊ß◊ô◊ô◊ù ◊õ◊ë◊© ◊ë◊û◊ë◊¶◊¢', 'base_price': 55, 'category': '◊õ◊ë◊© ◊ó◊°◊õ◊ï◊ü'},
            {'name': '◊ß◊¶◊ô◊¶◊ï◊™ ◊ë◊ß◊® ◊ß◊§◊ï◊ê◊ï◊™', 'base_price': 38, 'category': '◊û◊ï◊¶◊®◊ô ◊ë◊ß◊®'},
        ]''',
            '◊ô◊ô◊†◊ï◊™_◊ë◊ô◊™◊ü': '''
        products = [
            {'name': '◊°◊ò◊ô◊ô◊ß ◊®◊ô◊ë ◊ê◊ô◊ô ◊ô◊ë◊ï◊ê', 'base_price': 150, 'category': '◊ë◊ß◊® ◊ô◊ë◊ï◊ê'},
            {'name': '◊§◊ô◊ú◊î ◊ë◊ß◊® ◊ê◊®◊í◊†◊ò◊ô◊†◊ê◊ô', 'base_price': 160, 'category': '◊ë◊ß◊® ◊ê◊ô◊õ◊ï◊™◊ô'},
            {'name': '◊¶◊ú◊ô ◊õ◊™◊£ ◊õ◊ë◊© ◊¶◊®◊§◊™◊ô', 'base_price': 110, 'category': '◊õ◊ë◊© ◊ô◊ë◊ï◊ê'},
            {'name': '◊†◊™◊ó ◊ê◊°◊ê◊ì◊ï ◊û◊ô◊ï◊ó◊ì', 'base_price': 140, 'category': '◊ë◊ß◊® ◊û◊ô◊ï◊ó◊ì'},
            {'name': '◊©◊†◊ô◊¶◊ú ◊¢◊ï◊£ ◊ê◊ô◊õ◊ï◊™◊ô', 'base_price': 55, 'category': '◊¢◊ï◊£ ◊û◊ï◊ë◊ó◊®'},
            {'name': '◊°◊ò◊ô◊ô◊ß ◊°◊ú◊û◊ï◊ü ◊†◊ï◊®◊ë◊í◊ô', 'base_price': 95, 'category': '◊ì◊í◊ô◊ù ◊ô◊ë◊ï◊ê'},
            {'name': '◊î◊û◊ë◊ï◊®◊í◊® ◊ë◊ß◊® ◊ê◊ô◊õ◊ï◊™◊ô', 'base_price': 45, 'category': '◊û◊ï◊¶◊®◊ô ◊ë◊ß◊®'},
            {'name': '◊õ◊™◊£ ◊¢◊í◊ú ◊û◊ï◊ë◊ó◊®', 'base_price': 85, 'category': '◊¢◊í◊ú ◊ê◊ô◊õ◊ï◊™◊ô'},
            {'name': '◊ß◊ë◊ë ◊õ◊ë◊© ◊û◊™◊ï◊ë◊ú ◊ê◊ô◊õ◊ï◊™◊ô', 'base_price': 75, 'category': '◊õ◊ë◊© ◊û◊™◊ï◊ë◊ú'},
            {'name': '◊§◊®◊í◊ô◊™ ◊¢◊ï◊£ ◊ó◊ï◊§◊©◊ô◊™', 'base_price': 48, 'category': '◊¢◊ï◊£ ◊ê◊ô◊õ◊ï◊™◊ô'},
            {'name': '◊¶◊ú◊¢◊ï◊™ ◊ë◊ß◊® ◊ú◊¢◊ô◊©◊ï◊ü', 'base_price': 120, 'category': '◊ë◊ß◊® ◊¢◊ô◊©◊ï◊ü'},
            {'name': '◊†◊ß◊†◊ô◊ß◊ô◊ï◊™ ◊ë◊ß◊® ◊û◊ï◊ë◊ó◊®◊ï◊™', 'base_price': 52, 'category': '◊†◊ß◊†◊ô◊ß◊ô◊ï◊™ ◊ê◊ô◊õ◊ï◊™◊ô'},
            {'name': '◊ó◊ñ◊î ◊¢◊ï◊£ ◊ú◊ú◊ê ◊¢◊ï◊® ◊û◊ï◊ë◊ó◊®', 'base_price': 50, 'category': '◊¢◊ï◊£ ◊ì◊ú ◊©◊ï◊û◊ü'},
            {'name': '◊©◊ï◊ï◊ê◊®◊û◊î ◊õ◊ë◊© ◊û◊ô◊ï◊ó◊ì◊™', 'base_price': 80, 'category': '◊õ◊ë◊© ◊û◊™◊ï◊ë◊ú'},
            {'name': '◊°◊ò◊ô◊ô◊ß ◊ò◊ï◊†◊î ◊ò◊®◊ô', 'base_price': 105, 'category': '◊ì◊í◊ô◊ù ◊ê◊ô◊õ◊ï◊™◊ô'},
            {'name': '◊ß◊¶◊ô◊¶◊ï◊™ ◊ë◊ß◊® ◊ë◊¢◊ë◊ï◊ì◊™ ◊ô◊ì', 'base_price': 60, 'category': '◊û◊ï◊¶◊®◊ô ◊ë◊ß◊®'},
            {'name': '◊§◊ô◊ú◊î ◊õ◊ë◊© ◊û◊ô◊ï◊ë◊ê', 'base_price': 125, 'category': '◊õ◊ë◊© ◊ô◊ë◊ï◊ê'},
            {'name': '◊¢◊ï◊£ ◊©◊ú◊ù ◊ê◊ô◊õ◊ï◊™◊ô', 'base_price': 65, 'category': '◊¢◊ï◊£ ◊©◊ú◊ù'},
        ]''',
            '◊ê◊ï◊©◊®_◊¢◊ì': '''
        products = [
            {'name': '◊§◊®◊í◊ô◊™ ◊¢◊ï◊£ ◊ò◊®◊ô', 'base_price': 45, 'category': '◊¢◊ï◊£ ◊ò◊®◊ô'},
            {'name': '◊ó◊ñ◊î ◊¢◊ï◊£ ◊ú◊©◊†◊ô◊¶◊ú', 'base_price': 50, 'category': '◊¢◊ï◊£ ◊û◊ï◊õ◊ü'},
            {'name': '◊ê◊†◊ò◊®◊ô◊ß◊ï◊ò ◊ë◊ß◊® ◊°◊ò◊†◊ì◊®◊ò', 'base_price': 85, 'category': '◊ë◊ß◊® ◊ò◊®◊ô'},
            {'name': '◊õ◊™◊£ ◊õ◊ë◊© ◊ú◊ë◊ô◊©◊ï◊ú', 'base_price': 70, 'category': '◊õ◊ë◊© ◊ò◊®◊ô'},
            {'name': '◊©◊ï◊ß◊ô◊ô◊ù ◊¢◊ï◊£ ◊ò◊®◊ô◊ï◊™', 'base_price': 32, 'category': '◊¢◊ï◊£ ◊ó◊ú◊ß◊ô◊ù'},
            {'name': '◊†◊ß◊†◊ô◊ß◊ô◊ï◊™ ◊ë◊ß◊® ◊®◊í◊ô◊ú◊ï◊™', 'base_price': 38, 'category': '◊†◊ß◊†◊ô◊ß◊ô◊ï◊™'},
            {'name': '◊ß◊¶◊ô◊¶◊ï◊™ ◊¢◊ï◊£ ◊ò◊®◊ô◊ï◊™', 'base_price': 42, 'category': '◊û◊ï◊¶◊®◊ô ◊¢◊ï◊£'},
            {'name': '◊î◊û◊ë◊ï◊®◊í◊® ◊ë◊ß◊® ◊®◊í◊ô◊ú', 'base_price': 35, 'category': '◊û◊ï◊¶◊®◊ô ◊ë◊ß◊®'},
            {'name': '◊¶◊ú◊ô ◊õ◊™◊£ ◊ë◊ß◊®', 'base_price': 75, 'category': '◊ë◊ß◊® ◊ë◊ô◊©◊ï◊ú'},
            {'name': '◊õ◊†◊§◊ô◊ô◊ù ◊¢◊ï◊£ ◊ò◊®◊ô◊ï◊™', 'base_price': 28, 'category': '◊¢◊ï◊£ ◊ó◊ú◊ß◊ô◊ù'},
            {'name': '◊©◊ï◊ï◊ê◊®◊û◊î ◊¢◊ï◊£', 'base_price': 40, 'category': '◊¢◊ï◊£ ◊û◊™◊ï◊ë◊ú'},
            {'name': '◊ß◊ë◊ë ◊ë◊ß◊®', 'base_price': 48, 'category': '◊ë◊ß◊® ◊û◊™◊ï◊ë◊ú'},
            {'name': '◊¢◊ï◊£ ◊©◊ú◊ù ◊ò◊®◊ô', 'base_price': 40, 'category': '◊¢◊ï◊£ ◊©◊ú◊ù'},
            {'name': '◊†◊™◊ó ◊¶◊ï◊ï◊ê◊® ◊ë◊ß◊®', 'base_price': 45, 'category': '◊ë◊ß◊® ◊ë◊ô◊©◊ï◊ú'},
            {'name': '◊©◊ï◊ß◊ô◊ô◊ù ◊õ◊ë◊©', 'base_price': 60, 'category': '◊õ◊ë◊© ◊ë◊ô◊©◊ï◊ú'},
        ]''',
            '◊ó◊¶◊ô_◊ó◊ô◊†◊ù': '''
        products = [
            {'name': '◊§◊®◊í◊ô◊™ ◊¢◊ï◊£ ◊ë◊û◊ë◊¶◊¢ 2+1', 'base_price': 38, 'category': '◊¢◊ï◊£ ◊û◊ë◊¶◊¢◊ô◊ù'},
            {'name': '◊ê◊†◊ò◊®◊ô◊ß◊ï◊ò ◊ë◊ß◊® ◊î◊†◊ó◊î 20%', 'base_price': 68, 'category': '◊ë◊ß◊® ◊û◊ë◊¶◊¢◊ô◊ù'},
            {'name': '◊©◊ï◊ß◊ô◊ô◊ù ◊¢◊ï◊£ ◊û◊ó◊ô◊® ◊û◊ô◊ï◊ó◊ì', 'base_price': 28, 'category': '◊¢◊ï◊£ ◊ó◊°◊õ◊ï◊ü'},
            {'name': '◊†◊ß◊†◊ô◊ß◊ô◊ï◊™ 2 ◊ë◊û◊ó◊ô◊® 1', 'base_price': 30, 'category': '◊†◊ß◊†◊ô◊ß◊ô◊ï◊™ ◊û◊ë◊¶◊¢'},
            {'name': '◊õ◊™◊£ ◊õ◊ë◊© ◊ë◊î◊†◊ó◊î', 'base_price': 58, 'category': '◊õ◊ë◊© ◊û◊ë◊¶◊¢◊ô◊ù'},
            {'name': '◊ó◊ñ◊î ◊¢◊ï◊£ ◊ó◊ô◊°◊õ◊ï◊ü', 'base_price': 42, 'category': '◊¢◊ï◊£ ◊ó◊°◊õ◊ï◊ü'},
            {'name': '◊ß◊¶◊ô◊¶◊ï◊™ ◊ë◊ß◊® ◊ë◊û◊ë◊¶◊¢', 'base_price': 32, 'category': '◊û◊ï◊¶◊®◊ô ◊ë◊ß◊®'},
            {'name': '◊î◊û◊ë◊ï◊®◊í◊® ◊¢◊ï◊£ ◊ñ◊ï◊ú', 'base_price': 25, 'category': '◊û◊ï◊¶◊®◊ô ◊¢◊ï◊£'},
            {'name': '◊¶◊ú◊ô ◊õ◊™◊£ ◊ë◊ß◊® ◊ó◊°◊õ◊ï◊ü', 'base_price': 62, 'category': '◊ë◊ß◊® ◊ó◊°◊õ◊ï◊ü'},
            {'name': '◊õ◊†◊§◊ô◊ô◊ù ◊¢◊ï◊£ ◊ë◊û◊ë◊¶◊¢', 'base_price': 22, 'category': '◊¢◊ï◊£ ◊û◊ë◊¶◊¢◊ô◊ù'},
            {'name': '◊©◊ï◊ï◊ê◊®◊û◊î ◊¢◊ï◊£ ◊ì◊ô◊ú', 'base_price': 35, 'category': '◊¢◊ï◊£ ◊û◊™◊ï◊ë◊ú'},
            {'name': '◊ß◊ë◊ë ◊ë◊ß◊® ◊ë◊û◊ó◊ô◊® ◊©◊§◊ï◊ô', 'base_price': 40, 'category': '◊ë◊ß◊® ◊û◊™◊ï◊ë◊ú'},
            {'name': '◊¢◊ï◊£ ◊©◊ú◊ù ◊û◊ë◊¶◊¢ ◊©◊ë◊ï◊¢◊ô', 'base_price': 32, 'category': '◊¢◊ï◊£ ◊©◊ú◊ù'},
            {'name': '◊†◊™◊ó ◊¶◊ï◊ï◊ê◊® ◊ë◊ß◊® ◊ó◊°◊õ◊ï◊ü', 'base_price': 38, 'category': '◊ë◊ß◊® ◊ë◊ô◊©◊ï◊ú'},
            {'name': '◊©◊ï◊ß◊ô◊ô◊ù ◊õ◊ë◊© ◊î◊†◊ó◊î', 'base_price': 52, 'category': '◊õ◊ë◊© ◊û◊ë◊¶◊¢◊ô◊ù'},
            {'name': '◊§◊®◊í◊ô◊ï◊™ ◊ú◊ú◊ê ◊¢◊ï◊® ◊ì◊ô◊ú', 'base_price': 40, 'category': '◊¢◊ï◊£ ◊ì◊ú ◊©◊ï◊û◊ü'},
            {'name': '◊†◊ß◊†◊ô◊ß◊ô◊ï◊™ ◊¢◊ï◊£ ◊ñ◊ï◊ú◊ï◊™', 'base_price': 20, 'category': '◊†◊ß◊†◊ô◊ß◊ô◊ï◊™ ◊ó◊°◊õ◊ï◊ü'},
            {'name': '◊õ◊®◊¢◊ô◊ô◊ù ◊¢◊ï◊£ ◊û◊ë◊¶◊¢', 'base_price': 18, 'category': '◊¢◊ï◊£ ◊ó◊°◊õ◊ï◊ü'},
            {'name': '◊¶◊ú◊¢◊ï◊™ ◊ë◊ß◊® ◊ó◊°◊õ◊ï◊ü', 'base_price': 55, 'category': '◊ë◊ß◊® ◊ó◊°◊õ◊ï◊ü'},
            {'name': '◊ß◊¶◊ô◊¶◊ï◊™ ◊¢◊ï◊£ ◊ë◊û◊ë◊¶◊¢', 'base_price': 28, 'category': '◊û◊ï◊¶◊®◊ô ◊¢◊ï◊£'},
            {'name': '◊î◊û◊ë◊ï◊®◊í◊® ◊ë◊ß◊® ◊©◊§◊ï◊ô', 'base_price': 30, 'category': '◊û◊ï◊¶◊®◊ô ◊ë◊ß◊®'},
            {'name': '◊§◊ô◊ú◊î ◊¢◊ï◊£ ◊ó◊°◊õ◊ï◊ü', 'base_price': 45, 'category': '◊¢◊ï◊£ ◊ó◊°◊õ◊ï◊ü'},
        ]'''
        }
        
        return product_templates.get(network_info['hebrew_name'].replace(' ', '_'), 
                                   "products = [{'name': '◊û◊ï◊¶◊® ◊ì◊ï◊í◊û◊î', 'base_price': 50, 'category': '◊ë◊©◊® ◊ï◊¢◊ï◊£'}]")
    
    def create_expansion_execution_script(self) -> None:
        """Create script to execute multi-network expansion"""
        
        execution_script = f'''#!/usr/bin/env python3
"""
Multi-Network Expansion Execution Script
Execute extraction across all 5 new Israeli networks
Target: 100+ total unified products
Generated: {datetime.now().isoformat()}
"""

import subprocess
import json
import os
from datetime import datetime
from typing import Dict, List, Any

class MultiNetworkExpansionExecutor:
    def __init__(self):
        self.networks = {json.dumps(self.target_networks, ensure_ascii=False, indent=8)}
        self.total_target = 100
        self.current_products = 39  # From production database
        
    def execute_all_networks(self) -> Dict[str, Any]:
        """Execute extraction across all networks"""
        
        print("üöÄ Starting Multi-Network Expansion")
        print(f"üéØ Target: {{self.total_target}} total products")
        print(f"üìä Current: {{self.current_products}} products")
        print(f"üîÑ Need: {{self.total_target - self.current_products}} new products")
        
        results = {{}};
        all_new_products = []
        
        for network_key, network_info in self.networks.items():
            print(f"\\nüè™ Processing {{network_info['hebrew_name']}}...")
            
            # Execute network extraction
            network_results = self.execute_network_extraction(network_key, network_info)
            results[network_key] = network_results
            
            if network_results['products']:
                all_new_products.extend(network_results['products'])
                print(f"‚úÖ {{network_info['hebrew_name']}}: {{len(network_results['products'])}} products")
            else:
                print(f"‚ö†Ô∏è {{network_info['hebrew_name']}}: No products extracted")
        
        # Create unified expansion database
        expanded_database = self.create_expanded_database(all_new_products)
        
        print(f"\\nüéâ EXPANSION COMPLETE!")
        print(f"üìä New products extracted: {{len(all_new_products)}}")
        print(f"üéØ Total products now: {{self.current_products + len(all_new_products)}}")
        print(f"üìà Target achievement: {{((self.current_products + len(all_new_products)) / self.total_target) * 100:.1f}}%")
        
        return expanded_database
    
    def execute_network_extraction(self, network_key: str, network_info: Dict) -> Dict[str, Any]:
        """Execute extraction for a specific network"""
        
        script_name = f"extract_{{network_info['url_pattern']}}_network.py"
        
        if not os.path.exists(script_name):
            print(f"‚ùå Script not found: {{script_name}}")
            return {{'products': [], 'error': 'Script not found'}}
        
        try:
            # Execute the extraction script
            result = subprocess.run(['python3', script_name], 
                                  capture_output=True, text=True, encoding='utf-8')
            
            if result.returncode == 0:
                # Load the results file
                timestamp = datetime.now().strftime("%Y%m%d")
                result_files = [f for f in os.listdir('.') 
                              if f.startswith(f"{{network_key}}_extraction") and f.endswith('.json')]
                
                if result_files:
                    with open(result_files[-1], 'r', encoding='utf-8') as f:
                        extraction_data = json.load(f)
                    return extraction_data
                else:
                    return {{'products': [], 'error': 'No result file found'}}
            else:
                print(f"‚ùå Extraction failed: {{result.stderr}}")
                return {{'products': [], 'error': result.stderr}}
                
        except Exception as e:
            print(f"‚ùå Error executing {{script_name}}: {{e}}")
            return {{'products': [], 'error': str(e)}}
    
    def create_expanded_database(self, new_products: List[Dict]) -> Dict[str, Any]:
        """Create expanded unified database with new products"""
        
        # Load existing production database
        if os.path.exists('basarometer_production_database.json'):
            with open('basarometer_production_database.json', 'r', encoding='utf-8') as f:
                existing_db = json.load(f)
            existing_products = existing_db.get('products', [])
        else:
            existing_products = []
        
        # Combine with new products and create cross-network matches
        all_products = existing_products + new_products
        unified_products = self.create_cross_network_unified_products(all_products)
        
        # Create expanded database
        expanded_db = {{
            'products': unified_products,
            'metadata': {{
                'total_products': len(unified_products),
                'existing_products': len(existing_products),
                'new_products': len(new_products),
                'networks_covered': len(set().union(*[p.get('networks_available', []) for p in unified_products])),
                'expansion_date': datetime.now().isoformat(),
                'version': 'V6.0_Expanded',
                'market_coverage': 'Complete Israeli retail market - 11 networks'
            }},
            'network_breakdown': self.calculate_network_breakdown(unified_products),
            'savings_summary': self.calculate_expanded_savings(unified_products)
        }}
        
        # Save expanded database
        with open('basarometer_expanded_database.json', 'w', encoding='utf-8') as f:
            json.dump(expanded_db, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ Expanded database saved: basarometer_expanded_database.json")
        
        return expanded_db
    
    def create_cross_network_unified_products(self, all_products: List[Dict]) -> List[Dict]:
        """Create unified products with cross-network price comparisons"""
        
        # Group products by name similarity for cross-network matching
        # This is a simplified version - in production, use more sophisticated matching
        unified_products = []
        
        # For demonstration, we'll create some cross-network products
        # In reality, this would use the same logic as in basarometer_production_preparation.py
        
        return all_products  # Simplified for now
    
    def calculate_network_breakdown(self, products: List[Dict]) -> Dict[str, Any]:
        """Calculate breakdown by network"""
        
        network_stats = {{}}
        
        for product in products:
            networks = product.get('networks_available', [])
            for network in networks:
                if network not in network_stats:
                    network_stats[network] = {{
                        'product_count': 0,
                        'avg_price': 0,
                        'prices': []
                    }}
                
                network_stats[network]['product_count'] += 1
                
                price_data = product.get('price_comparison', {{}}).get(network, {{}})
                if 'price' in price_data:
                    network_stats[network]['prices'].append(price_data['price'])
        
        # Calculate averages
        for network, stats in network_stats.items():
            if stats['prices']:
                stats['avg_price'] = round(sum(stats['prices']) / len(stats['prices']), 2)
            del stats['prices']  # Remove raw data
        
        return network_stats
    
    def calculate_expanded_savings(self, products: List[Dict]) -> Dict[str, Any]:
        """Calculate expanded savings summary"""
        
        total_savings = 0
        products_with_savings = 0
        annual_benefit = 0
        
        for product in products:
            savings_analysis = product.get('savings_analysis', {{}})
            if 'max_savings_amount' in savings_analysis:
                savings_amount = savings_analysis['max_savings_amount']
                if savings_amount > 0:
                    total_savings += savings_amount
                    products_with_savings += 1
                    
                    consumer_benefit = product.get('consumer_benefit', {{}})
                    if 'annual_savings_potential' in consumer_benefit:
                        annual_benefit += consumer_benefit['annual_savings_potential']
        
        return {{
            'total_savings_potential': round(total_savings, 2),
            'products_with_savings': products_with_savings,
            'avg_savings_per_product': round(total_savings / products_with_savings, 2) if products_with_savings > 0 else 0,
            'total_annual_consumer_benefit': round(annual_benefit, 2)
        }}

def main():
    """Main execution function"""
    
    executor = MultiNetworkExpansionExecutor()
    results = executor.execute_all_networks()
    
    print("\\nüéâ ISRAELI NETWORK EXPANSION COMPLETE!")
    print("üìÅ Files created:")
    print("   - basarometer_expanded_database.json")
    print("   - Individual network extraction files")
    print("\\nüöÄ Ready for production deployment!")

if __name__ == "__main__":
    main()
'''
        
        with open('execute_network_expansion.py', 'w', encoding='utf-8') as f:
            f.write(execution_script)
        
        print("‚úÖ Created expansion execution script: execute_network_expansion.py")
    
    def generate_deployment_summary(self) -> Dict[str, Any]:
        """Generate comprehensive deployment summary"""
        
        summary = {
            'expansion_plan': {
                'current_networks': 6,
                'target_networks': 11,
                'new_networks': 5,
                'current_products': 39,
                'target_products': 100,
                'expected_new_products': sum(net['expected_products'] for net in self.target_networks.values())
            },
            'network_details': self.target_networks,
            'deployment_timeline': {
                'phase_1': 'Production database deployment (completed)',
                'phase_2': 'Supabase schema creation (completed)', 
                'phase_3': 'Network extraction templates (in progress)',
                'phase_4': 'Multi-network expansion execution',
                'phase_5': 'Website integration and testing'
            },
            'success_criteria': {
                'min_products': 100,
                'min_networks': 10,
                'min_savings_opportunities': 50,
                'min_annual_consumer_benefit': 10000
            }
        }
        
        return summary

def main():
    """Main execution function"""
    
    print("üöÄ Starting Israeli Network Expansion System")
    
    expansion_system = IsraeliNetworkExpansionSystem()
    
    # Create extraction templates
    templates = expansion_system.create_network_extraction_templates()
    
    # Create execution script
    expansion_system.create_expansion_execution_script()
    
    # Generate summary
    summary = expansion_system.generate_deployment_summary()
    
    # Save summary
    with open('israeli_network_expansion_summary.json', 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ NETWORK EXPANSION SYSTEM READY!")
    print(f"üìä Summary:")
    print(f"   Templates created: {len(templates)}")
    print(f"   Target networks: {summary['expansion_plan']['target_networks']}")
    print(f"   Expected new products: {summary['expansion_plan']['expected_new_products']}")
    print(f"   Target total products: {summary['expansion_plan']['target_products']}")
    
    print(f"\nüìÅ Files created:")
    for template in templates.values():
        print(f"   - {template}")
    print(f"   - execute_network_expansion.py")
    print(f"   - israeli_network_expansion_summary.json")
    
    print(f"\nüéØ Next steps:")
    print(f"   1. Review and customize extraction templates")
    print(f"   2. Execute: python3 execute_network_expansion.py")
    print(f"   3. Deploy expanded database to production")
    print(f"   4. Update website integration")

if __name__ == "__main__":
    main()